—Neural Style Transfer (NST) has emerged as a
powerful technique for artistic image synthesis by fusing the
base image with style source. In this study, we present a
comparative analysis of NST using popular convolutional neural
network (CNN) architectures, using pre-trained models such
as VGG19, DenseNet121, ResNet50, and MobileNetV2. The
methodology involves leveraging the deep features extracted by
the models to balance content and style in synthesized images.
We delve into the specifics of the model’s layer utilization,
loss function definition, and TensorFlow implementation details.
Experimental results demonstrate the model’s ability to produce
visually compelling images that seamlessly merge content and
style characteristics. Densenet121 has demonstrated superior
performance compared to the other models in the evaluation.
This work not only contributes to the field of NST but also
offers a user-friendly TensorFlow framework, fostering further
exploration and advancements in the realm of computer vision
and image processing.
