Neural Style Transfer (NST) is a powerful technique for creating artistic images by blending the content of a base image with the style of a source image. This study presents a comparative analysis of NST using popular convolutional neural network (CNN) architectures, including pre-trained models like VGG19, DenseNet121, ResNet50, and MobileNetV2. The approach focuses on leveraging deep features extracted by these models to achieve a balance between content and style in the synthesized images. Key aspects such as layer selection, loss function definition, and implementation in TensorFlow are explored in detail. 

The experimental results highlight the ability of the models to produce visually striking images that effectively merge content and style features. Among the models evaluated, DenseNet121 demonstrates superior performance. This work not only enhances the understanding of NST but also provides a user-friendly TensorFlow framework, encouraging further research and innovation in computer vision and image processing.
